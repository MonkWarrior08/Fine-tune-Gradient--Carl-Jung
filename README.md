# Carl Jung Conversation Fine-Tuning for Nous-Hermes-Llama2-13b
LLM model: Nous-Hermes-Llama2-13b

Notebook Colab public link access: https://colab.research.google.com/drive/1fT2wJmTVi5An9KoiUKYMBhhxXCLVGmx7?usp=sharing

This repository contains the code and resources for fine-tuning the Nous-Hermes-Llama2-13b language model with Carl Jung conversation data. The project aims to create a model that can engage in Jungian-style psychological discussions and provide insights based on Carl Jung's theories.

Key Features:
Fine-tuning of Nous-Hermes-Llama2-13b model
Training data based on user-Carl Jung conversations (specialize in Ni congnitive function)
Focus on Jungian psychology concepts and personality insights

Usage:
The fine-tuning process is implemented in a Google Colab notebook, which is publicly accessible (provided above). Due to the model's size, it cannot be run locally. Instead, we use Gradient to run the LLM.
To test the model:

Open the Colab notebook
Run the required code segment chronologically. Requires your own gradient account and ID to interact with the fine-tuned model. Carl Jung data can be downloaded from the main repo (csv file).


Feel free to contribute, provide feedback, or use this model for your own.
